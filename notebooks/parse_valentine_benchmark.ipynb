{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf88e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e93d2a",
   "metadata": {},
   "source": [
    "## Fabricated Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3723234b-10b7-4406-9084-3842f7d6ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(path, new_dir):\n",
    "    json_files = [pos_json for pos_json in os.listdir(path) if \"mapping\" in pos_json]\n",
    "    if not json_files:\n",
    "        return\n",
    "    json_file = json_files[0]\n",
    "    \n",
    "    tables = [table for table in os.listdir(path) if table.endswith(\".csv\")]\n",
    "    \n",
    "    source_tab = [table for table in tables if \"source\" in table][0]\n",
    "    target_tab = [table for table in tables if \"target\" in table][0]\n",
    "    \n",
    "    df_dict = {\n",
    "        \"source_col\": [],\n",
    "        \"target_col\": [],\n",
    "        \"source_tab\": [],\n",
    "        \"target_tab\": []\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(path, json_file)) as f:\n",
    "        d = json.load(f)\n",
    "\n",
    "        for match in d['matches']:\n",
    "            print(match[\"source_column\"], match[\"target_column\"])\n",
    "            df_dict[\"source_col\"].append(match[\"source_column\"])\n",
    "            df_dict[\"target_col\"].append(match[\"target_column\"])\n",
    "            df_dict[\"source_tab\"].append(source_tab.split(\".\")[0])\n",
    "            df_dict[\"target_tab\"].append(target_tab)\n",
    "            \n",
    "\n",
    "    source_df = pd.read_csv(os.path.join(path, source_tab))\n",
    "    target_df = pd.read_csv(os.path.join(path, target_tab))\n",
    "    source_df.to_csv(os.path.join(new_dir, \"source-tables\", source_tab), index=False)\n",
    "    target_df.to_csv(os.path.join(new_dir, \"target-tables\", target_tab), index=False)\n",
    "\n",
    "    return pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc4304ad-5f16-4b9c-b5e0-331d68897731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikidata\n",
      "Joinable\n",
      "musician musicianID\n",
      "birthDate birthDate\n",
      "familyNameLabel familyName\n",
      "givenNameLabel forename\n",
      "numberOfChildren NChildren\n",
      "websiteLabel webpage\n",
      "Semantically-Joinable\n",
      "musician musicianID\n",
      "musicianLabel musicianName\n",
      "genderLabel genderType\n",
      "cityLabel city\n",
      "fatherLabel fatherName\n",
      "motherLabel motherName\n",
      "partner spouse\n",
      "genreLabel kind\n",
      "Unionable\n",
      "musician musicianID\n",
      "musicianLabel musicianName\n",
      "genderLabel genderType\n",
      "birthDate birthDate\n",
      "cityLabel city\n",
      "familyNameLabel familyName\n",
      "givenName forename\n",
      "fatherLabel fatherName\n",
      "motherLabel motherName\n",
      "partner spouse\n",
      "numberOfChildren NChildren\n",
      "genreLabel kind\n",
      "websiteLabel webpage\n",
      "residenceLabel residence\n",
      "ethnicityLabel ethnicity\n",
      "religionLabel religionLabel\n",
      "activityStart kickoff\n",
      "twitterNameLabel twitterUsername\n",
      "geniusNameLabel geniusNameLabel\n",
      "recordLabelLabel recordCompany\n",
      "View-Unionable\n",
      "musician musicianID\n",
      "birthDate birthDate\n",
      "familyNameLabel familyName\n",
      "givenName forename\n",
      "numberOfChildren NChildren\n",
      "websiteLabel webpage\n"
     ]
    }
   ],
   "source": [
    "types = [\"Joinable\", \"Semantically-Joinable\", \"Unionable\", \"View-Unionable\"]\n",
    "datasets = [\"ChEMBL\", \"OpenData\", \"TPC-DI\", \"Wikidata\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    for type in types:\n",
    "        print(type)\n",
    "        root = \"./Valentine-datasets/\" + dataset + \"/\" + type\n",
    "        new_dir = \"./valentine/\" + dataset + \"/\" + type\n",
    "\n",
    "        if not os.path.exists(new_dir):\n",
    "            os.makedirs(new_dir)\n",
    "            os.makedirs(new_dir + \"/source-tables\")\n",
    "            os.makedirs(new_dir + \"/target-tables\")\n",
    "\n",
    "        ground_truth = pd.DataFrame(columns=[\"source_col\", \"target_col\", \"source_tab\", \"target_tab\"])\n",
    "\n",
    "        for _, dirs, _ in os.walk(root):\n",
    "            for dir in dirs:\n",
    "                print(dir)\n",
    "                df = read_json_file(os.path.join(root, dir), new_dir)\n",
    "                if df is None:\n",
    "                    continue\n",
    "\n",
    "                ground_truth = pd.concat([ground_truth, df], ignore_index=True)\n",
    "                \n",
    "        if dataset == \"Wikidata\":\n",
    "            df = read_json_file(root, new_dir)\n",
    "            ground_truth = pd.concat([ground_truth, df], ignore_index=True)\n",
    "\n",
    "        ground_truth.to_csv(os.path.join(new_dir, \"matches.csv\"), index=False)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997e5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_google_exp\n",
      "id id\n",
      "title title\n",
      "manufacturer manufacturer\n",
      "price price\n",
      "dblp_acm\n",
      "id id\n",
      "title title\n",
      "authors authors\n",
      "venue venue\n",
      "year year\n",
      "walmart_amazon\n",
      "id id\n",
      "title title\n",
      "category category\n",
      "brand brand\n",
      "modelno modelno\n",
      "price price\n",
      "dblp_scholar\n",
      "id id\n",
      "title title\n",
      "authors authors\n",
      "venue venue\n",
      "year year\n",
      "beeradvo_ratebeer\n",
      "id id\n",
      "Beer_Name Beer_Name\n",
      "Brew_Factory_Name Brew_Factory_Name\n",
      "Style Style\n",
      "ABV ABV\n",
      "itunes_amazon\n",
      "id id\n",
      "Song_Name Song_Name\n",
      "Artist_Name Artist_Name\n",
      "Album_Name Album_Name\n",
      "Genre Genre\n",
      "Price Price\n",
      "CopyRight CopyRight\n",
      "Time Time\n",
      "Released Released\n",
      "fodors_zagats\n",
      "id id\n",
      "name name\n",
      "addr addr\n",
      "city city\n",
      "phone phone\n",
      "type type\n",
      "class class\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Magellan\"\n",
    "root = \"./Valentine-datasets/\" + dataset\n",
    "new_dir = \"./valentine/\" + dataset\n",
    "\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "    os.makedirs(new_dir + \"/source-tables\")\n",
    "    os.makedirs(new_dir + \"/target-tables\")\n",
    "\n",
    "ground_truth = pd.DataFrame(columns=[\"source_col\", \"target_col\", \"source_tab\", \"target_tab\"])\n",
    "\n",
    "for _, dirs, _ in os.walk(root):\n",
    "    for dir in dirs:\n",
    "        print(dir)\n",
    "        df = read_json_file(os.path.join(root, dir), new_dir)\n",
    "        if df is None:\n",
    "            continue\n",
    "\n",
    "        ground_truth = pd.concat([ground_truth, df], ignore_index=True)\n",
    "\n",
    "ground_truth.to_csv(os.path.join(new_dir, \"matches.csv\"), index=False)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57552c1d-0387-4173-8da3-cb88363f36c9",
   "metadata": {},
   "source": [
    "## Biomedical Pretrain: Create joined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98575394-3e1a-470c-b214-75eccbf66a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "usecases = [\"cao\", \"dou\", \"clark\", \"huang\", \"krug\", \"satpathy\", \"vasaikar\", \"wang\"]\n",
    "\n",
    "df_all = pd.DataFrame({})\n",
    "for usecase in usecases:\n",
    "    df = pd.read_csv(os.path.join(usecase, \"source.csv\")).sample(50)\n",
    "    df_all = pd.concat([df_all, df], sort=False)\n",
    "df_all\n",
    "\n",
    "df_all.to_csv(\"gdc_all/source.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d093907c-cbd9-4439-8eb9-68f2385ede2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_usecases = [\"cao\", \"dou\", \"clark\", \"huang\"]\n",
    "\n",
    "gt_all = pd.DataFrame({})\n",
    "\n",
    "for usecase in train_usecases:\n",
    "    df = pd.read_csv(os.path.join(usecase, \"groundtruth.csv\"))\n",
    "    gt_all = pd.concat([gt_all, df], sort=False)\n",
    "gt_all = gt_all.drop_duplicates()\n",
    "gt_all\n",
    "\n",
    "gt_all.to_csv(\"gdc_all/groundtruth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e6dd0-5256-4ce9-9e1c-47ecd2e0ee52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
